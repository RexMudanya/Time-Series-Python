{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years.\n",
    "The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute.\n",
    "\n",
    "It is a multivariate series comprised of seven variables (besides the date and time); they are:\n",
    "\n",
    "1. global_active_power: The total active power consumed by the household (kilowatts).\n",
    "2. global_reactive_power: The total reactive power consumed by the household (kilowatts).\n",
    "3. voltage: Average voltage (volts).\n",
    "4. global_intensity: Average current intensity (amps).\n",
    "5. sub_metering_1: Active energy for kitchen (watt-hours of active energy).\n",
    "6. sub_metering_2: Active energy for laundry (watt-hours of active energy).\n",
    "7. sub_metering_3: Active energy for climate control systems (watt-hours of active energy).\n",
    "\n",
    "A fourth sub-metering variable can be created by subtracting the sum of three defined sub-metering variables from the total active energy as follows:\n",
    "sub_metering_remainder = (global_active_power * 1000 / 60) - (sub_metering_1 + sub_metering_2 + sub_metering_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. read and combine the 1st 2 columns into date-time column used as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from pandas import to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Global_active_power Global_reactive_power  Voltage  \\\n",
      "datetime                                                                 \n",
      "2006-12-16 17:24:00               4.216                 0.418  234.840   \n",
      "2006-12-16 17:25:00               5.360                 0.436  233.630   \n",
      "\n",
      "                    Global_intensity Sub_metering_1 Sub_metering_2  \\\n",
      "datetime                                                             \n",
      "2006-12-16 17:24:00           18.400          0.000          1.000   \n",
      "2006-12-16 17:25:00           23.000          0.000          1.000   \n",
      "\n",
      "                     Sub_metering_3  \n",
      "datetime                             \n",
      "2006-12-16 17:24:00            17.0  \n",
      "2006-12-16 17:25:00            16.0  \n"
     ]
    }
   ],
   "source": [
    "# load all the data\n",
    "dataset = read_csv('data/household_power_consumption.txt', sep=';',\n",
    "                   header=0, low_memory=False, \n",
    "                   infer_datetime_format=True, \n",
    "                   parse_dates={'datetime':[0,1]}, \n",
    "                   index_col=['datetime'])\n",
    "\n",
    "print(dataset.head(2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Replace missing values '?' with Nan\n",
    "3. Make dataset Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark all missing values\n",
    "dataset.replace('?', nan, inplace=True)\n",
    "\n",
    "# make dataset numeric\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Fill missing values by copying observation from same time the day before\n",
    "    -- fill_missing() take a numpy array of date & copy values from exactly 24 hrs ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "\tone_day = 60 * 24\n",
    "\tfor row in range(values.shape[0]):\n",
    "\t\tfor col in range(values.shape[1]):\n",
    "\t\t\tif isnan(values[row, col]):\n",
    "\t\t\t\tvalues[row, col] = values[row - one_day, col]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. create a new column containing remainder of submetering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Save cleaned data to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated dataset\n",
    "dataset.to_csv('data/cleaned/household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Framing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QUEST: Given recent power consumption, what is the expected power consumption for the week ahead?\n",
    "\n",
    "SOLN: Requires a predictive model forecast total active power for each day over next 7 days.\n",
    "    -- Framing of dataset requires downsampling to daily totals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 8)\n",
      "            Global_active_power  Global_reactive_power    Voltage  \\\n",
      "datetime                                                            \n",
      "2006-12-16             1209.176                 34.922   93552.53   \n",
      "2006-12-17             3390.460                226.006  345725.32   \n",
      "2006-12-18             2203.826                161.792  347373.64   \n",
      "2006-12-19             1666.194                150.942  348479.01   \n",
      "2006-12-20             2225.748                160.998  348923.61   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
      "datetime                                                                       \n",
      "2006-12-16            5180.8             0.0           546.0          4926.0   \n",
      "2006-12-17           14398.6          2033.0          4187.0         13341.0   \n",
      "2006-12-18            9247.2          1063.0          2621.0         14018.0   \n",
      "2006-12-19            7094.0           839.0          7602.0          6197.0   \n",
      "2006-12-20            9313.0             0.0          2648.0         14063.0   \n",
      "\n",
      "            sub_metering_4  \n",
      "datetime                    \n",
      "2006-12-16    14680.933319  \n",
      "2006-12-17    36946.666732  \n",
      "2006-12-18    19028.433281  \n",
      "2006-12-19    13131.900043  \n",
      "2006-12-20    20384.800011  \n"
     ]
    }
   ],
   "source": [
    "# load the new file\n",
    "dataset = read_csv('data/cleaned/household_power_consumption.csv',\n",
    "                   header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('data/cleaned/household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "use new dataset for fitting and evaluating predictive models for the chosen framing of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluation Metric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Forecast will be comprised of 7 values for each day of the week ahead\n",
    "forecasted time steps are evaluated seperately to:\n",
    " - coment on the skill at a specific load time (e.g +1dy vs +5dys)\n",
    " - contrast models based on skill at different load times (e.g models good at +1dy vs @ +5 dys)\n",
    "\n",
    "Use Root Mean Standard Error(RMSE) as error metric for power in kilowatts.\n",
    "RMSE also used as performance metric for each lead time from day 1 to day 7.\n",
    "RMSE also used to summarise model performance using a single score to aid model selection\n",
    "\n",
    "evaluate_forecast() implements this behaviour and returns model performance based on multiple 7 day forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Returns overall RMSE regardless of day, then an array of RMSE scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Test Sets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Training Set = first 3yrs \n",
    "2. Test Set = final year\n",
    "\n",
    "Data is divided into standard weeks SUN-SAT working backwards from test data\n",
    "\n",
    "Final Year : 2010 1ST,SUN: 3, JAN yr ends in mid NOV 2010 closest SAT: 20, NOV, 46 wks(test set)\n",
    "Start from: 1ST,SUN: 17, DEC, 2006 , standard weeks = 159 (training)\n",
    "\n",
    "split_data(), splits daily data into train+test set and organizes each into standard weeks\n",
    "Use specific row offsets to split data using dataset knowledge\n",
    "the split dataset is then organised into weekly data using NumPy split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "\t# split into standard weeks\n",
    "\ttrain, test = data[1:-328], data[-328:-6]\n",
    "    \n",
    "\t# restructure into windows of weekly data\n",
    "\ttrain = array(split(train, len(train)/7))\n",
    "\ttest = array(split(test, len(test)/7))\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can test this function out by loading the daily dataset and printing the first and last rows of data from both the train and test sets to confirm they match the expectations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 7, 8)\n",
      "3390.46 1308.8359999999998\n",
      "(46, 7, 8)\n",
      "2083.4539999999984 2197.006000000004\n"
     ]
    }
   ],
   "source": [
    "from numpy import split\n",
    "from numpy import array\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "\t# split into standard weeks\n",
    "\ttrain, test = data[1:-328], data[-328:-6]\n",
    "\t# restructure into windows of weekly data\n",
    "\ttrain = array(split(train, len(train)/7))\n",
    "\ttest = array(split(test, len(test)/7))\n",
    "\treturn train, test\n",
    " \n",
    "# load the new file\n",
    "dataset = read_csv('data/cleaned/household_power_consumption_days.csv',\n",
    "                   header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "train, test = split_dataset(dataset.values)\n",
    "# validate train data\n",
    "print(train.shape)\n",
    "print(train[0, 0, 0], train[-1, -1, 0])\n",
    "# validate test\n",
    "print(test.shape)\n",
    "print(test[0, 0, 0], test[-1, -1, 0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Running the example shows that indeed the train dataset has 159 weeks of data, whereas the test dataset has 46 weeks.\n",
    "We can see that the total active power for the train and test dataset for the first and last rows match the data for the specific dates that we defined as the bounds on the standard weeks for each set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Evaluation Scheme:\n",
    "    Model required to make 1wk prediction then actual data is made available to the model so that it can be used\n",
    "    as a basis for making a prediction on subsequent week.\n",
    "    \n",
    "evaluate_model() - train & test sets provided as arguments, n_input used to define number of prior observations model will use as input to make prediction\n",
    "\n",
    "build_model() - builds the model\n",
    "forecast() - use model to forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "once evaluated performance can be summarized\n",
    "summarize_scores() - display performance of a model as a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
